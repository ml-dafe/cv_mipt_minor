{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Семинар №1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Работа с растровыми изображенями**\n",
    "**Растровое изображение** $-$ изображение, представляющее собой сетку пикселей — цветных точек. \n",
    "Важными характеристиками изображения являются: размер, глубина цвета и цветовое пространство.\n",
    "\n",
    "<img src=\"img/RGB_cube.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "Самый распространённый способ выделить объект $-$ это цвет.\n",
    "\n",
    "**Цвет** $-$ это свойство тел отражать или испускать видимое излучение определенного спектрального состава и интенсивности.\n",
    "\n",
    "Трихроматическая теория (сетчатка глаза имеет 3 вида рецепторов света, ответственных за цветное зрение) полагает, что достаточно всего трёх чисел, чтобы описать цвет (красный, синий, зелёный). Т.е. используя три значения **R, G, B**  \n",
    "\n",
    "Цветовые пространства бывают линейные и нелинейные.\n",
    "К линейным относится **RGB**. Изучим его подробней."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T18:37:11.081019Z",
     "start_time": "2020-09-09T18:37:10.673419Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# отображение графиков в ноутбуке\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T18:37:11.110304Z",
     "start_time": "2020-09-09T18:37:11.101698Z"
    }
   },
   "outputs": [],
   "source": [
    "# считаем изображение\n",
    "image = cv2.imread('img/RGB_cube.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T18:37:11.140225Z",
     "start_time": "2020-09-09T18:37:11.133244Z"
    }
   },
   "outputs": [],
   "source": [
    "# посмотрим, какой тип объекта \n",
    "type(image), image.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T18:37:11.216364Z",
     "start_time": "2020-09-09T18:37:11.211365Z"
    }
   },
   "outputs": [],
   "source": [
    "# размерность\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T18:37:11.540211Z",
     "start_time": "2020-09-09T18:37:11.440169Z"
    }
   },
   "outputs": [],
   "source": [
    "# преобразуем RGB в BGR для корректного отображения\n",
    "# это необходимо из-за особенностей matplotlib\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# отобразим объект\n",
    "plt.imshow(image)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grayscale\n",
    "\n",
    "**Grayscale** - цветовой режим изображений, которые отображаются в оттенках серого цвета, размещённые в виде таблицы в качестве эталонов яркости белого цвета.\n",
    "\n",
    "В компьютерном представлении широко распространённая серая шкала использует на каждый пиксел изображения один байт ($8$ бит) информации. Такая шкала передаёт $256$ оттенков (градаций) серого цвета, или яркости (значение $0$ представляет чёрный цвет, а значение $255$ $-$ белый).\n",
    "\n",
    "<img src=\"img/grad_grayscale.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "\n",
    "Преобразование цветного изображения в оттенки серого из **RGB** пересчитывают по формуле:\n",
    "\n",
    "\\begin{align}\n",
    "\\ Y' & = 0.2126R + 0.7152G + 0.0722B \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В **OpenCV_** сменить цветовой режим изображения можно с помощью функции **cv2.cvtColor(img, code)**\n",
    "\n",
    "* **img** $-$ исходное изображение\n",
    "* **code** $-$ кодировка для смены цвета. \n",
    "\n",
    "Все кодировки есть в [документации](https://docs.opencv.org/3.4/d8/d01/group__imgproc__color__conversions.html#ga397ae87e1288a81d2363b61574eb8cab). В рамках занятий мы рассмотрим лишь их часть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T18:37:13.203942Z",
     "start_time": "2020-09-09T18:37:13.045342Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# создадим grayscale изображение с помощью openCV\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize = (12, 8))\n",
    "ax1, ax2 = axs\n",
    "\n",
    "ax1.set_title('RGB изображение', fontsize=15)\n",
    "ax1.imshow(image)\n",
    "ax2.set_title('Grayscale изображение', fontsize=15)\n",
    "ax2.imshow(gray_image, cmap='gray')\n",
    "\n",
    "axs = [ax.axis('off') for ax in axs.flatten()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Поиграемся с каналами\n",
    "Выделим каналы изображения. Они представимы как массивы чисел, поэтому не составит труда их разделить из исходного изобрадения. Посмоторим на картинку, где есть только красный, зеленый и синий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T18:37:14.021767Z",
     "start_time": "2020-09-09T18:37:14.012912Z"
    }
   },
   "outputs": [],
   "source": [
    "# R scale\n",
    "r = image[:, :, 2].copy()\n",
    "r[(r >= 250) & (r <= 250)] = 0\n",
    "\n",
    "# G scale\n",
    "g = image[:, :, 1].copy()\n",
    "g[(g >= 250) & (g <= 250)] = 0\n",
    "\n",
    "# B scale\n",
    "b = image[:, :, 0].copy()\n",
    "b[(b >= 250) & (b <= 250)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T18:37:14.635180Z",
     "start_time": "2020-09-09T18:37:14.395564Z"
    }
   },
   "outputs": [],
   "source": [
    "## посмотрим на результат\n",
    "fig, axs = plt.subplots(1, 4, figsize = (20, 9))\n",
    "ax1, ax2, ax3, ax4 = axs\n",
    "\n",
    "ax1.set_title('R канал', fontsize=15)\n",
    "ax1.imshow(r, cmap='gray')\n",
    "ax2.set_title('G канал', fontsize=15)\n",
    "ax2.imshow(g, cmap='gray')\n",
    "ax3.set_title('B канал', fontsize=15)\n",
    "ax3.imshow(b, cmap='gray')\n",
    "ax4.set_title('RGB', fontsize=15)\n",
    "ax4.imshow(image)\n",
    "\n",
    "axs = [ax.axis('off') for ax in axs.flatten()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Контрольные вопросы:***\n",
    "\n",
    "1. Почему так получилось?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте изменим конфигурацию каналов, чтобы посмотреть на изменения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T18:37:15.595865Z",
     "start_time": "2020-09-09T18:37:15.590040Z"
    }
   },
   "outputs": [],
   "source": [
    "tr_val = 155  # пороговое значение\n",
    "\n",
    "# R scale\n",
    "r = image[:, :, 2].copy()\n",
    "r[r < tr_val] = 0\n",
    "\n",
    "# G scale\n",
    "g = image[:, :, 1].copy()\n",
    "g[g < tr_val] = 0\n",
    "\n",
    "# B scale\n",
    "b = image[:, :, 0].copy()\n",
    "b[b < tr_val] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T18:37:16.226166Z",
     "start_time": "2020-09-09T18:37:15.988584Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## посмотрим на результат\n",
    "fig, axs = plt.subplots(1, 4, figsize = (20, 9))\n",
    "ax1, ax2, ax3, ax4 = axs\n",
    "\n",
    "ax1.set_title('R канал', fontsize=15)\n",
    "ax1.imshow(r, cmap='gray')\n",
    "ax2.set_title('G канал', fontsize=15)\n",
    "ax2.imshow(g, cmap='gray')\n",
    "ax3.set_title('B канал', fontsize=15)\n",
    "ax3.imshow(b, cmap='gray')\n",
    "ax4.set_title('RGB', fontsize=15)\n",
    "ax4.imshow(image)\n",
    "\n",
    "axs = [ax.axis('off') for ax in axs.flatten()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Контрольные вопросы:***\n",
    "\n",
    "1. Какой вывод можно сделать из этих примеров?\n",
    "\n",
    "2. Чем неудобна **RGB** кодировка цвета?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поиск по цвету"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бывают задачи, в которых отличительной особенностью предмета являтются его цветовые признаки. Рассмотрим пример:\n",
    "\n",
    "<img src=\"img/cat.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "Как мы можем в этом найти кота? Для начала мы можем оценить глазами, что цвет кота отличается от цвета окружения – он ярко рыжий и отлично виден в траве. Как мы можем выделить этот цвет в OpenCV? Для этого существует специальная функция ```cv2.inRange(image, low_color, max_color)```, она принимает на вход изображение и диапазон цвета, который мы хотим выделить. **На выходе мы получаем черно-белое изображение**, где белым выделены пиксели, цвета которых попадали в диапазон, а черным $-$ все другое. Дальше мы попробуем найти кота."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding Windows\n",
    "\n",
    "В классическом CV есть устоявшееся идея про скользящие окна, к которой еще не раз будем ссылаться в курсе. Идея очень простая и понятна из названия - будем пробегать неким окном по изображению и выполнять какие-то функции в каждом окне. Что конкретно делать и когда уже зависит от конкретной задачи и алгоритма. Пока сделаем само скользящее окно, чтобы использовать его дальше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T18:37:17.915686Z",
     "start_time": "2020-09-09T18:37:17.910636Z"
    }
   },
   "outputs": [],
   "source": [
    "# создадим генератор для скользящего окна\n",
    "def sliding_window(image, stepSize, windowSize):\n",
    "    # скользим по каждому индексу с заданным шагом\n",
    "    for y in range(0, image.shape[0], stepSize):\n",
    "        for x in range(0, image.shape[1], stepSize):\n",
    "            # возвращаем текущее окно\n",
    "            yield (x, y, image[y:y + windowSize[1], x:x + windowSize[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T18:37:27.120967Z",
     "start_time": "2020-09-09T18:37:19.451447Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# размеры скользящего окна\n",
    "winW, winH = 64, 64\n",
    "step = 32\n",
    "\n",
    "# loop over the sliding window for each layer of the pyramid\n",
    "for (x, y, window) in sliding_window(image, stepSize=step, windowSize=(winW, winH)):\n",
    "    # if the window does not meet our desired window size, ignore it\n",
    "    if window.shape[0] != winH or window.shape[1] != winW:\n",
    "        continue\n",
    "\n",
    "    # в этом месте идет какая-то фугкция обработки окна\n",
    "\n",
    "    # отрисуем окно для наглядности \n",
    "    clone = image.copy()\n",
    "    cv2.rectangle(clone, (x, y), (x + winW, y + winH), (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Sliding Windows\", clone)\n",
    "    cv2.waitKey(1)\n",
    "    time.sleep(0.025)\n",
    "    \n",
    "cv2.destroyAllWindows();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Найди кота\n",
    "\n",
    "Теперь попробуем найти кота на изображении с помощью реализованного поиска цвета выше. Одако вот так искать цвет для конкретного объекта в цветом пространстве RGB трудно. Рассмотрим пример для наглядности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-09-09T18:37:28.548Z"
    }
   },
   "outputs": [],
   "source": [
    "# посмторим на кота\n",
    "\n",
    "cat_image  = cv2.imread('img/cat.jpg')\n",
    "\n",
    "while True:\n",
    "    cv2.imshow('cat', cat_image)\n",
    "    \n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T18:37:37.297198Z",
     "start_time": "2020-09-09T18:37:37.245238Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_image  = cv2.imread('img/cat.jpg')\n",
    "\n",
    "# значения цвета можно посмотреть в gimp или paint\n",
    "pix = 256\n",
    "low_red = (0.0 * pix, 0.11 * pix, 0.37 * pix)\n",
    "high_red = (0.35 * pix, 0.4 * pix, 0.99 * pix)\n",
    "\n",
    "cat_area = cv2.inRange(cat_image, low_red, high_red)\n",
    "\n",
    "# посмотрим на результат\n",
    "fig, m_axs = plt.subplots(1, 2, figsize = (12, 9))\n",
    "ax1, ax2 = m_axs\n",
    "\n",
    "ax1.set_title('Исходная картинка', fontsize=15)\n",
    "cat_image = cv2.cvtColor(cat_image, cv2.COLOR_BGR2RGB)  # преобразуем цвет для plt\n",
    "ax1.imshow(cat_image, cmap='gray')\n",
    "ax1.axis('off')\n",
    "\n",
    "ax2.set_title('Только кот', fontsize=15)\n",
    "ax2.imshow(cat_area, cmap='gray')\n",
    "ax2.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Кот в RGB $-$ не кот. Выбираем цветовое пространство.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С данным изображением мы уже можем работать, но что-то в нем не то. Кот выделен не целиком, и есть много лишних точек. На самом деле, мы научимся даже из такого получать много полезной информации, но в данный момент мы сделаем одно очень важное и правильное улучшение. Как вы могли заметить $-$ мы работаем с изображением в пространстве **RGB**. У данного пространства, кроме не очевидной для человеческого восприятия записи цвета, есть еще один недостаток в нашем случае. Чтобы его понять, рассмотрим что из себя представляет **RGB**:\n",
    "\n",
    "<img src=\"img/RGB_cube_scheme.png\" alt=\"Drawing\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пространство представляет из себя куб с длинной стороны $256$, где любой цвет задается координатами соответствующей точки на данном кубе. Данная концепция получила широкое распространение из-за того, что в случае формирования цвета на экране устройства, такого как телефон или монитор компьютера, изображение формируется за счет точек трех цветов $-$ синего, зеленого, и красного. Теперь перейдем к нашей функции ```cv2.inRange()```. Она принимает набор из двух цветов – точек на данном кубе. Что в таком случае мы будем считать за цвет, который удовлетворяет нашим критериям? Для ответа на данный вопрос нарисуем схематично тот же самый куб RGB:\n",
    "\n",
    "<img src=\"img/RGB_scheme.png\" alt=\"Drawing\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данной схеме становится понятно, что пространство между двумя заданными точками цвета также является кубом RGB. Таким образом, наша функция находит вложенный цветовой куб в полном кубе RGB. Кроме того, что это может непонятно звучать, это и работает не самым лучшим образом: представим что мы хотим найти оттенки пурпурного цвета, в таком случае мы размещаем наш вложенный куб как можно ближе к пурпурному. Но при таком размещении, мы так или иначе затрагиваем все остальные цвета, из-за того, что стороны куба параллельны основному. Как в таком случае поступить?\n",
    "\n",
    "Мы не первые,кто сталкивается с такой задачей и такой проблемой. И одно из существующих решений $-$ переход в другое цветовое пространство. Если поставить задачей, что во главе угла у нас фиксируется оттенок цвета или соотношение между RGB, то мы приходим к следующей схеме:\n",
    "\n",
    "<img src=\"img/RGB_HSV_trans.png\" alt=\"Drawing\" style=\"width: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной модели мы переходим к следующим координатам $-$ **оттенок, насыщенность и значение**. Именно в данных понятиях люди обычно описывают цвета. \n",
    "\n",
    "Под цветовым тоном (**Hue**) имеют в виду именно цвет (длину волны). \n",
    "\n",
    "Насыщенность (**Saturation**) характеризует близость цвета к белому (розовый ближе к белому чем красный). \n",
    "\n",
    "Значение (**Value**) описывается всех сложнее и в модели HS ее можно описать как общую яркость точки или цвета.\n",
    "\n",
    "Все серые цвета (лежащие на диагонали куба) при этом проецируются в центральную точку. Чтобы с помощью этой модели можно было закодировать все цвета, доступные в RGB-модели, необходимо добавить вертикальную ось яркости (или интенсивности) (I). В итоге получается:\n",
    "\n",
    "<img src=\"img/HSV.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "В OpenCV диапазоны разные. S, V находятся в $[0,255]$, а H – в $[0,180]$. Обычно H находится в диапазоне $[0,360]$ (полный круг), но для того, чтобы поместиться в байте ($256$ различных значений), его значение уменьшается вдвое.\n",
    "\n",
    "В пространстве HSV проще отделить один цвет, так как вы можете просто установить правильный диапазон для H и просто позаботиться о том, чтобы S не был слишком маленьким (он будет почти белым), а V не слишком мал (это будет темно).\n",
    "\n",
    "Например, если вам нужны почти синие цвета, вам нужно, чтобы H находилось вокруг значения $120$ (например, в $[110,130]$), а S, V не слишком мало (скажем, в $[100, 255]$).\n",
    "\n",
    "Белый цвет не является оттенком (радуга не имеет белого цвета в нем), но представляет собой комбинацию цвета.\n",
    "\n",
    "В HSV вам нужно взять весь диапазон H (H в $[0, 180]$), очень малые значения S (например, S в $[0, 25]$) и очень высокие значения V (например, V в $[230, 255]$). Это в основном соответствует верхней части центральной оси конуса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном конусе диапазон выбранных цветов будет представлять из себя конический слой. Его главные для нас атрибуты: он лежит по оттенку в заданных пределах, в отличии от RGB, его светлота и интенсивность также определяются просто и очевидно в описании цветового предела. Благодаря таким удобным и полезным свойствам данное цветовое пространство заслужило большую любовь как среди дизайнеров, так и особенно среди общества разработчиков компьютерного зрения. \n",
    "\n",
    "В OpenCV данное цветовое пространство имеет обозначение **HSV**. Переведем наше изображение в него и снова найдем котейку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T04:31:50.070577Z",
     "start_time": "2020-07-15T04:31:49.811350Z"
    }
   },
   "outputs": [],
   "source": [
    "# меняем цветовое пространство\n",
    "cat_image_hsv = cv2.cvtColor(cat_image, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "# осталось только подобрать нужные цвета \n",
    "# воспользуйтесь функциями, которые реализовали выше\n",
    "hsv_low = (0, 0, 0)\n",
    "hsv_high = (0, 0, 0)\n",
    "\n",
    "cat_area = cv2.inRange(cat_image_hsv, hsv_low, hsv_high)\n",
    "\n",
    "## посмотрим на результат\n",
    "fig, m_axs = plt.subplots(1, 2, figsize = (12, 9))\n",
    "ax1, ax2 = m_axs\n",
    "\n",
    "ax1.set_title('Исходная картинка', fontsize=15)\n",
    "ax1.imshow(cat_image, cmap='gray')\n",
    "ax2.set_title('Только кот', fontsize=15)\n",
    "ax2.imshow(cat_area, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут я лишь остановлюсь на моменте выбора цвета, в данном примере мы руководствовались лишь собственным глазом и оценкой того, какой цвет мы хотим найти. Этим **HSV** замечательно отличается от **RGB**, в которой нам необходимо каждый цвет искать в справочнике или использовать сторонние программы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Краткое ревью элементов из линейной алгебры**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Связанные определения\n",
    "\n",
    "**Квадратной** называется матрица, у которой число строк равно числу столбцов.\n",
    "\n",
    "**Нулевой** ($Θ$) называется матрица, у которой все элементы равны 0.\n",
    "\n",
    "**Главной диагональю** матрицы называется набор элементов, у которых индекс строк равен индексу столбцов, то есть идущая из левого верхнего угла в правый нижний.\n",
    "\n",
    "**Побочной диагональю** матрицы называется набор элементов, расположенных на диагонали, идущей из левого нижнего угла в правый верхний.\n",
    "\n",
    "**Единичной** ($E$) называется квадратная матрица, у которой на главной диагонали стоят единицы, а все остальные равны нулю.\n",
    "\n",
    "**Симметричной** называется такая квадратная матрица, у которой для всех элементов выполняется условие $a_{i,j} = a_{j,i}$.\n",
    "\n",
    "**Диагональной** называется такая матрица, у которой элементы не лежащие на главной диагонали равны нулю."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Транспонирование матриц\n",
    "\n",
    "Матрица $A^T$ называется **транспонированной** матрицей $A$, если для любого элемента $A^T_{i,j} = A_{j,i}$. Иными словами, отперация транспонирования -- это отражение матрицы относительно ее главной диагонали. \n",
    "\n",
    "Для симметричной матрицы $S = S^T$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сложение матриц\n",
    "Складывать можно только матрицы одинакового размера.\n",
    "\n",
    "Сложение матриц $A+B$ есть операция нахождения матрицы $C$, все элементы которой равны попарной сумме всех соответствующих элементов матриц $A$ и $B$, то есть каждый элемент матрицы $C$ равен: $$\\displaystyle c_{i,j} = a_{i,j} + b_{i,j}$$\n",
    "\n",
    "### Свойства сложения матриц:\n",
    "\n",
    "* коммутативность: $A+B = B+A$\n",
    "* ассоциативность: $(A+B)+C =A+(B+C)$;\n",
    "* сложение с нулевой матрицей: $A + Θ = A$;\n",
    "* существование противоположной матрицы: $A + (-A) = Θ$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Умножение матриц\n",
    "\n",
    "Умножение матриц (обозначение:  $AB$, реже со знаком умножения  $A\\times B$) — есть операция вычисления матрицы $C$, каждый элемент которой равен сумме произведений элементов в соответствующей строке первого множителя и столбце второго.\n",
    "\n",
    "$c_{ij}=\\sum _{k=1}^{n}a_{ik}b_{kj}$\n",
    "Количество столбцов в матрице $A$ должно совпадать с количеством строк в матрице $B$, иными словами, матрица $A$ обязана быть согласованной с матрицей $B$. Если матрица $A$ имеет размерность $m\\times n$, $B$ — $n \\times k$, то размерность их произведения $A B = C$ есть $m \\times k$.\n",
    "\n",
    "<img src=\"img/AdotB.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "\n",
    "### Свойства умножения матриц:\n",
    "\n",
    "* ассоциативность: $(AB)C = A(BC)$;\n",
    "* антикоммутативность (в общем случае): $AB$ $\\neq$  $BA$;\n",
    "* произведение коммутативно в случае умножения с единичной матрицей: $AE = EA$;\n",
    "* дистрибутивность: $(A+B)C = AC + BC, \\: A(B+C) = AB + AC$;\n",
    "* ассоциативность и коммутативность относительно умножения на число: $(\\lambda A)B = \\lambda (AB) = A(\\lambda B)$.\n",
    "\n",
    "Подробное объяснение умножения матриц вместе с примерами можно найти [тут](http://mathprofi.ru/deistviya_s_matricami.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Афинные преобразования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Под преобразованием понимается отображение множества на себя. Другими словами, преобразование $-$ это правило, в соответствии с которым каждому элементу множества ставится в соответствие элемент этого же множества.\n",
    "\n",
    "Преобразование плоскости (пространства) называется аффинным, если существуют такие две аффинные системы координат, что координаты любой точки в первой системе координат совпадают с координатами ее образа во второй системе координат.\n",
    "\n",
    "Аффинное преобразование можно рассматривать как последовательное применение (композицию) двух отображений:\n",
    "\n",
    "Точке ставится в соответствие координаты относительно первой системы координат;\n",
    "Полученным координатам ставится в соответствие точка относительно второй системы координат.\n",
    "Пусть $f$ $-$ аффинное преобразование. Рассмотрим вектор ${\\overrightarrow{AB}}$ в первой системе координат и ${\\overrightarrow{f(A)f(B)}}$ во второй. Так как координаты вектора определяются как разность координат конца и начала, а координаты точек ${A}$ и ${f(A)}$, $B$ и ${f(B)}$ равны в соответствующих системах координат, то вектор ${\\overrightarrow{f(A)f(B)}}$ имеет те же координаты относительно второй системы координат, что и вектор ${\\overrightarrow{AB}}$ относительно первой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Аффинные преобразования плоскости\n",
    "\n",
    "Преобразование плоскости задается двумя скалярными функциями двух переменных:\n",
    "\n",
    "${\\begin{cases}\\hat{x}=f_{1}(x,y)\\\\ \\hat{y}=f_{2}(x,y)\\end{cases}}$ или аналогично через вектор-функцию ${\\begin{pmatrix}f_1(x);\\ f_2(x)\\end{pmatrix}^T}$\n",
    "\n",
    "#### Формула аффинного преобразования плоскости\n",
    "\n",
    "Преобразование $A$ плоскости называется аффинным, если координаты $(\\hat{x},\\hat{y})$ образа $Y$ выражаются через координаты $(x,y)$ прообраза $X \\ (Y=A(X))$ по формулам:\n",
    "\n",
    "$$\n",
    "{\\begin{cases}\\hat{x}=a_{11}x+a_{12}y-x_{0}\\\\ \\hat{y}=a_{21}x+a_{22}y-y_{0}\\end{cases}} {\\Leftrightarrow\\quad} \n",
    "{{\\begin{pmatrix}\\hat{x}\\\\\\hat{y}\\end{pmatrix}}=A{\\begin{pmatrix}x\\\\y\\end{pmatrix}} - {\\begin{pmatrix}x_{0}\\\\y_{0}\\end{pmatrix}},}\n",
    "$$\n",
    "\n",
    "где матрица ${\\begin{equation*}A={\\begin{pmatrix}a_{11}\\ a_{12}\\\\a_{21}\\ a_{22}\\end{pmatrix}}\\end{equation*}}$\n",
    "$-$ невырожденная матрица (матрица аффинного преобразования).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Свойства аффинных преобразований плоскости\n",
    "__1.__ Аффинное преобразование взаимно однозначное, кроме того:\n",
    "\n",
    "* преобразование, обратное к аффинному, является также аффинным;\n",
    "* композиция аффинных преобразований является также аффинным преобразованием.\n",
    "***\n",
    "__2.__ При аффинном преобразовании векторы преобразуются следующим образом:\n",
    "\n",
    "* равные векторы $-$ в равные;\n",
    "* коллинеарные $-$ в коллинеарные, причем отношение коллинеарных векторов сохраняется;\n",
    "* неколлинеарные $-$ в неколлинеарные.\n",
    "***\n",
    "__3.__ При аффинном преобразовании сохраняется отношение, в котором точка делит отрезок.\n",
    "***\n",
    "__4.__ При аффинном преобразовании площадь любого параллелограмма изменяется в одном и том же отношении, т.е. умножается на одно и то же число (называемое коэффициентом искажения площади):\n",
    "\n",
    "$\\hat{S}=|det|\\cdot S$, где\n",
    "\n",
    "$S$ $-$ площадь параллелограмма,\n",
    "\n",
    "$\\hat{S}$ $-$ площадь образа этого параллелограмма. \n",
    "\n",
    "Другими словами, коэффициент искажения площади при аффинном преобразовании равен модулю определителя матрицы этого преобразования."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Геометрические преобразования изображений**\n",
    "\n",
    "Теперь мы рассмотрим каким образом аффинные преобразования помогут нам изменять изображения с помощью OpenCV.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Однородные координаты\n",
    "\n",
    "А что же делать? Колдовать! Представьте теперь, что я допишу руками одну строчку и один столбец к нашей матрице преобразования и добавлю третью координату, которая равна единице у вектора, который мы преобразовываем:\n",
    "\n",
    "$$\n",
    "{\\begin{pmatrix} a && b && e\\\\ c && d && f\\\\ 0 && 0 && 1 \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} ax + by + e \\\\ cx + dy + f \\\\ 1 \\end{pmatrix}}\n",
    "$$\n",
    "\n",
    "При умножении этой 3x3 матрицы и нашего вектора, дополненного единицей, мы снова получили вектор с единицей в третьей компоненте, а остальные две имеют ровно тот вид, который мы хотели! Колдунство.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сдвиг изображения\n",
    "**Сдвиг** $-$ это смещение местоположения объекта. Если вам известно смещение в направлении $(x,y)$, пусть оно будет $(tx,ty)$, вы можете создать матрицу преобразования $M$ следующим образом:\n",
    "\n",
    "$$\n",
    "\\ M = \\begin{pmatrix}\n",
    "1 & \\ 0 & \\ t_x \\\\ \n",
    "0 & \\ 1 & \\ t_y \\\\  \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Затем вы можете взять массив Numpy типа np.float32 и передать его в функцию **cv2.warpAffine()**. Ниже приведен пример сдвига:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T04:32:00.121144Z",
     "start_time": "2020-07-15T04:31:59.713189Z"
    }
   },
   "outputs": [],
   "source": [
    "# сдвиг изображения\n",
    "\n",
    "image  = cv2.imread('img/RGB_cube.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "## посмотрим на размер изображения\n",
    "print('Раземер исходного изображения:', image.shape)\n",
    "rows, cols, _ = image.shape\n",
    "\n",
    "## матрица афинного преобразования\n",
    "M1 = np.float32([[1, 0, 200], [0, 1, 0]])\n",
    "M2 = np.float32([[1, 0, 0], [0, 1, 200]])\n",
    "M3 = np.float32([[1, 0, 200], [0, 1, 200]])\n",
    "\n",
    "## визуализация\n",
    "fig, m_axs = plt.subplots(1, 3, figsize=(20,8))\n",
    "ax1, ax2, ax3 = m_axs\n",
    "\n",
    "dst1 = cv2.warpAffine(image.copy(), M1, (cols, rows))\n",
    "ax1.imshow(dst1)\n",
    "ax1.grid()\n",
    "ax1.set_title('M1 преоразование', fontsize=15)\n",
    "\n",
    "dst2 = cv2.warpAffine(image.copy(), M2, (cols, rows))\n",
    "ax2.imshow(dst2)\n",
    "ax2.grid()\n",
    "ax2.set_title('M2 преоразование', fontsize=15)\n",
    "\n",
    "dst3 = cv2.warpAffine(image.copy(), M3, (cols, rows))\n",
    "ax3.imshow(dst3)\n",
    "ax3.grid()\n",
    "ax3.set_title('M3 преоразование', fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поворот изображения\n",
    "Поворот изображения на угол $\\theta$ достигается путем преобразования матрицы вида:\n",
    "\n",
    "$$\n",
    "\\ M = \\begin{pmatrix}\n",
    "\\cos(\\theta) & \\ -\\sin(\\theta) \\\\ \n",
    "\\sin(\\theta) & \\ \\cos(\\theta) \\\\  \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Но OpenCV обеспечивает масштабированное вращение с регулируемым центром вращения, так что вы можете вращаться в любом месте, которое вы предпочитаете. Модифицированная матрица преобразования задается:\n",
    "\n",
    "$$\n",
    "\\ M = \\begin{pmatrix}\n",
    "\\alpha & \\ -\\beta & \\ (1-\\alpha)\\cdot center.x - \\beta \\cdot center.y \\\\ \n",
    "\\beta & \\ \\alpha & \\ \\beta \\cdot center/x + (1-\\alpha) \\cdot center.y \\\\  \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "где: \n",
    "\n",
    "$$\n",
    "\\alpha = scale \\cdot \\cos(\\theta) \\\\\n",
    "\\beta = scale \\cdot \\sin(\\theta) \\\\ \n",
    "$$ \n",
    "\n",
    "Результатом поворота является:\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix} \\ x' \\\\ \\ y' \\\\ \\end{pmatrix} = \n",
    "\\begin{pmatrix}\n",
    "\\alpha & \\ -\\beta & \\ (1-\\alpha)\\cdot center.x - \\beta \\cdot center.y \\\\ \n",
    "\\beta & \\ \\alpha & \\ \\beta \\cdot center/x + (1-\\alpha) \\cdot center.y \\\\ \n",
    "\\end{pmatrix} \\cdot \n",
    "\\begin{pmatrix} \\ x \\\\ \\ y \\\\ 1 \\\\ \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "где:\n",
    "\n",
    "$$\n",
    "\\ (x', y') - \\ new \\ coordinates \\\\\n",
    "\\ (x, y) - \\ old \\ coordinates \\\\ \n",
    "$$\n",
    "Чтобы найти эту матрицу преобразования, OpenCV предоставляет функцию **cv2.getRotationMatrix2D()**. Ниже приведены несколько примеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T04:32:01.785434Z",
     "start_time": "2020-07-15T04:32:01.393908Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Раземер исходного изображения:', image.shape)\n",
    "rows, cols, _ = image.shape\n",
    "\n",
    "M1 = cv2.getRotationMatrix2D((cols/2, rows/2), 25, scale=1.0)\n",
    "M2 = cv2.getRotationMatrix2D((300, 700), -15, scale=0.75)\n",
    "M3 = cv2.getRotationMatrix2D((300, 100), 45, scale=2.0)\n",
    "\n",
    "## визуализация\n",
    "fig, m_axs = plt.subplots(1, 3, figsize=(20, 8))\n",
    "ax1, ax2, ax3 = m_axs\n",
    "\n",
    "dst1 = cv2.warpAffine(image.copy(), M1, (cols, rows))\n",
    "ax1.imshow(dst1)\n",
    "ax1.grid()\n",
    "ax1.set_title('M1 преоразование', fontsize=15)\n",
    "\n",
    "dst2 = cv2.warpAffine(image.copy(), M2, (cols, rows))\n",
    "ax2.imshow(dst2)\n",
    "ax2.grid()\n",
    "ax2.set_title('M2 преоразование', fontsize=15)\n",
    "\n",
    "dst3 = cv2.warpAffine(image.copy(), M3, (cols, rows))\n",
    "ax3.imshow(dst3)\n",
    "ax3.grid()\n",
    "ax3.set_title('M3 преоразование', fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Контрольные вопросы:***\n",
    "Как сделать поворт изображения без обрезаний краев? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Трансформация точек\n",
    "При аффинном преобразовании все параллельные линии в исходном изображении все еще будут параллельны в выходном изображении. Чтобы найти матрицу преобразования, нам нужны три точки из входного изображения и их соответствующие местоположения в выходном изображении. Затем **cv2.getAffineTransform()** создаст матрицу $2\\times 3$, которая должна быть передана в **cv2.warpAffine()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T04:32:02.910243Z",
     "start_time": "2020-07-15T04:32:02.640612Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Раземер исходного изображения:', image.shape)\n",
    "h, w, _ = image.shape\n",
    "\n",
    "pts1 = np.float32([[50, 50], [400, 50], [50, 200]])\n",
    "pts2 = np.float32([[100, 100], [200, 20], [100, 250]]) \n",
    "\n",
    "M = cv2.getAffineTransform(pts1, pts2) \n",
    "print(f'Матрица перехода: \\n{M}')\n",
    "\n",
    "dst = cv2.warpAffine(image, M, (w, h))\n",
    "\n",
    "fig, m_axs = plt.subplots(1, 2, figsize=(12, 8))\n",
    "ax1, ax2 = m_axs\n",
    "\n",
    "ax1.set_title('Исходное изображение', fontsize=15)\n",
    "ax1.imshow(image)\n",
    "ax1.grid()\n",
    "ax1.scatter(*pts1.T, color='g', s=100)\n",
    "\n",
    "ax2.set_title('M преобразование', fontsize=15)\n",
    "ax2.imshow(dst)\n",
    "ax2.grid()\n",
    "ax2.scatter(*pts2.T, color='g', s=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Перспектива\n",
    "\n",
    "На самом деле, идея очень простая: параллельный перенос не является линейной операцией в двумерном пространстве.\n",
    "Поэтому мы погружаем наше двумерное пространство в трёхмерное (добавив единицу в третью компоненту). Это означает, что наше двумерное пространство это плоскость z=1 внутри трёхмерного. Затем мы делаем линейное преобразование в трёхмерном пространстве и проецируем всё трехмерное пространство обратно на нашу физическую плоскость. Параллельный перенос от этого не стал линеен, но пайплайн всё же прост.\n",
    "\n",
    "\n",
    "\n",
    "Как именно мы проецируем трёхмерное пространство обратно в нашу плоскость? Очень просто:\n",
    "\n",
    "$$\n",
    "{\\begin{pmatrix} x \\\\ y \\\\ z\\end{pmatrix} \\rightarrow \\begin{pmatrix} x/z \\\\ y/z \\end{pmatrix}}\n",
    "$$\n",
    "\n",
    "Итак, если мы хотим построить центральную перспективу, находящейся на оси z на расстоянии c от начала координат, то сначала мы погружаем трёхмерные точки в четырёхмерное пространство, добавив 1. Затем умножаем на следующую матрицу и проецируем результат обратно в 3D:\n",
    "\n",
    "$$\n",
    "{\\begin{pmatrix} x \\\\ y \\\\ z\\end{pmatrix} \\rightarrow \\begin{pmatrix} x \\\\ y \\\\ z \\\\ 1\\end{pmatrix}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "{\\begin{pmatrix} 1 && 0 && 0 && 0 \\\\ 0 && 1 && 0 && 0 \\\\ 0 && 0 && 1 && 0 \\\\ 0 && 0 && -1/c && 1\\end{pmatrix} \\begin{pmatrix} x \\\\ y \\\\ z \\\\ 1\\end{pmatrix} = \\begin{pmatrix} x \\\\ y \\\\ z \\\\ 1 - z/c\\end{pmatrix}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "{\\begin{pmatrix} x \\\\ y \\\\ z \\\\ 1 - z/c\\end{pmatrix} \\rightarrow \\begin{pmatrix} \\frac{x}{1-z/c} \\\\ \\frac{y}{1-z/c} \\\\ \\frac{z}{1-z/c}\\end{pmatrix}}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для преобразования перспективы вам понадобится матрица преобразования $3\\times3$. Прямые линии останутся прямыми даже после трансформации. Чтобы найти эту матрицу преобразования, вам нужно $4$ точки на входном изображении и соответствующие точки на выходном изображении. Среди этих $4$ точек $3$ из них не должны быть коллинеарными. Тогда матрица преобразования может быть найдена функцией **cv2.getPerspectiveTransform()**. Затем примените **cv2.warpPerspective()** с этой матрицей преобразования $3\\times3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T04:32:04.184022Z",
     "start_time": "2020-07-15T04:32:03.783679Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Раземер исходного изображения:', image.shape)\n",
    "rows, cols, _ = image.shape\n",
    "\n",
    "pts1 = np.float32([[200, 100], [450, 100],[200, 400], [450, 400]])\n",
    "pts2 = np.float32([[0, 0],[cols/2, 0],[0, rows], [cols, rows]]) \n",
    "pts3 = np.float32([[0, 0],[cols, 0],[0, rows], [cols, rows/2]]) \n",
    "\n",
    "M1 = cv2.getPerspectiveTransform(pts1, pts2) \n",
    "M2 = cv2.getPerspectiveTransform(pts1, pts3) \n",
    "\n",
    "fig, m_axs = plt.subplots(1, 3, figsize=(20,8))\n",
    "ax1, ax2, ax3 = m_axs\n",
    "\n",
    "ax1.set_title('Исходное изображение', fontsize=15)\n",
    "ax1.imshow(image)\n",
    "ax1.grid()\n",
    "ax1.scatter(*pts1.T, color='g', s=100)\n",
    "\n",
    "ax2.set_title('M1 преобразование', fontsize=15)\n",
    "dst2 = cv2.warpPerspective(image, M1, (cols, rows))\n",
    "ax2.imshow(dst2)\n",
    "ax2.grid()\n",
    "\n",
    "ax3.set_title('M2 преобразование', fontsize=15)\n",
    "dst3 = cv2.warpPerspective(image, M2, (cols, rows))\n",
    "ax3.imshow(dst3)\n",
    "ax3.grid();"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
